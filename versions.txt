# LLM Platform - Version History
# ================================
# Format: [DATE] [VERSION] - [COMPONENT] - [DESCRIPTION]
# 
# ARCHITECTURE:
# - CloudFlare (Edge): Landing pages, API Gateway, KV cache, D1, R2
# - DigitalOcean (Backend): PostgreSQL+pgvector, Redis, Ollama LLM
# - Supabase: User auth
# ================================

[2025-12-28] v0.1.0 - INITIAL - Project structure
  - cloudflare/workers/api-gateway: API entry with rate limiting
  - cloudflare/workers/mcp-search-api: Web search
  - digitalocean/docker-compose.yml: PostgreSQL, Redis, Ollama
  - Removed n8n (custom agents instead)

[2025-12-28] v0.2.0 - DATABASE + MODEL
  - Applied PostgreSQL schema with pgvector
  - Tables: users, documents, conversations, messages, agent_tasks
  - Loaded llama3.2:1b model to Ollama (1.3GB)
  - Added landing page for CloudFlare Pages

  DEPLOYED:
  - API: https://llm-api-gateway.mindnetworksassociation.workers.dev
  - GitHub: https://github.com/mindnetworksassociation-collab/ai-platform
  - Droplet: 164.92.231.18 (fra1)
  - Model: llama3.2:1b ready

  NEXT:
  - Deploy landing to CloudFlare Pages
  - Connect API Gateway â†’ Ollama via Cloudflare Tunnel
  - Add embedding generation for RAG
